安装docker_kafka服务
首先需要必要的docker及docker-compose

kafka是由zookeeper来进行管理，所以需要pull kafka和zookeeper这两个docker镜像

docker pull wurstmeister/zookeeper

docker pull wurstmeister/kafka

启动zookeeper镜像生成容器
docker run -d --name zookeeper -p 2181:2181 -v /etc/localtime:/etc/localtime wurstmeister/zookeeper


启动kafka镜像生成容器
docker run -d --name kafka -p 9092:9092 -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=192.168.1.19:2181/kafka -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.19:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -v /etc/localtime:/etc/localtime wurstmeister/kafka



-e KAFKA_BROKER_ID=0  在kafka集群中，每个kafka都有一个BROKER_ID来区分自己
-e KAFKA_ZOOKEEPER_CONNECT=192.168.155.56:2181/kafka 配置zookeeper管理kafka的路径192.168.155.56:2181/kafka
-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.155.56:9092  把kafka的地址端口注册给zookeeper
-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 配置kafka的监听端口
-v /etc/localtime:/etc/localtime 容器时间同步虚拟机的时间


验证kafka注册消息队列



进入容器
docker exec -it kafka /bin/sh进入路径：/opt/kafka_2
进入路径：/opt/kafka_2.11-2.0.0/bin下
运行kafka生产者发送消息./kafka-console-producer.sh --broker-list localhost:9092 --topic sun
发送消息
{"datas":[{"channel":"","metric":"temperature","producer":"ijinus","sn":"IJA0101-00002245","time":"1543207156000","value":"80"}],"ver":"1.0"}


运行kafka消费者接收消息
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic sun --from-beginning



docker-compose创建并启动kafka服务

version: '2'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
  kafka:
    image: wurstmeister/kafka
#   volumes:
#     - /etc/localtime:/etc/localtime
    build: .
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 192.168.1.19
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
	  
	  
创建kafka群集(Swarm模式)  
启动kafka—manager,并在kafka_manager中启用JMX服务监听
version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    volumes:
      - /user/kafka_data/zookeeper:/opt/zookeeper-3.4.13/data


  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
#    volumes:
#      - /user/kafka_data/kafka:/kafka
#      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 192.168.1.19
      KAFKA_MESSAGE_MAX_BYTES: 2000000
      KAFKA_CREATE_TOPICS: "Topic1:1:3,Topic2:1:1:compact"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

  kafka-manager:
    image: sheepkiller/kafka-manager
    ports:
      - "9020:9000"
    environment:
      ZK_HOSTS: zookeeper:2181

在创建好Swarm群集的基础上启动docker-compose多容器
启动多个容器服务如：
sudo docker stack deploy -c ./docker-compose.yml docker
	  
	  
在kafka_manager中启用JMX监听，jmx端口主要用来监控kafka集群的
在启动kafka的脚本kafka-server-start.sh中找到堆设置，添加export JMX_PORT="9999"
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"
    export JMX_PORT="9999"
fi


